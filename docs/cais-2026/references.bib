%% References for CAIS 2026 Paper
%% Klaudbiusz: Evaluation Framework for Autonomous Databricks Application Generation

%% Code Generation Benchmarks
@article{chen2021evaluating,
  title={Evaluating Large Language Models Trained on Code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and de Oliveira Pinto, Henrique Ponde and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@article{austin2021program,
  title={Program Synthesis with Large Language Models},
  author={Austin, Jacob and Odena, Augustus and Nye, Maxwell and Bosma, Maarten and Michalewski, Henryk and Dohan, David and Jiang, Ellen and Cai, Carrie and Terry, Michael and Le, Quoc and others},
  journal={arXiv preprint arXiv:2108.07732},
  year={2021}
}

%% Repository-Level Benchmarks
@article{jimenez2024swe,
  title={SWE-bench: Can Language Models Resolve Real-World GitHub Issues?},
  author={Jimenez, Carlos E and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2310.06770},
  year={2024}
}

@article{yang2024swe,
  title={SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering},
  author={Yang, John and Jimenez, Carlos E and Wettig, Alexander and Liber, Kilian and Yao, Shunyu and Narasimhan, Karthik and Press, Ofir},
  journal={arXiv preprint arXiv:2405.15793},
  year={2024}
}

%% Agent Evaluation Frameworks
@article{zhou2024webarena,
  title={WebArena: A Realistic Web Environment for Building Autonomous Agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Bisk, Yonatan and Fried, Daniel and Alon, Uri and others},
  journal={arXiv preprint arXiv:2307.13854},
  year={2024}
}

@article{mialon2023gaia,
  title={GAIA: A Benchmark for General AI Assistants},
  author={Mialon, Gr{\'e}goire and Dess{\`i}, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raez, Roberta and Rozi{\`e}re, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and others},
  journal={arXiv preprint arXiv:2311.12983},
  year={2023}
}

%% DevOps and Software Delivery
@book{forsgren2018accelerate,
  title={Accelerate: The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations},
  author={Forsgren, Nicole and Humble, Jez and Kim, Gene},
  year={2018},
  publisher={IT Revolution Press}
}

%% Related Agent Systems
@article{zhang2024autocoder,
  title={AutoCodeRover: Autonomous Program Improvement},
  author={Zhang, Yuntao and Ruan, Haifeng and Fan, Zhiyu and Roychoudhury, Abhik},
  journal={arXiv preprint arXiv:2404.05427},
  year={2024}
}

@article{xia2024agentless,
  title={Agentless: Demystifying LLM-based Software Engineering Agents},
  author={Xia, Chunqiu Steven and Deng, Yinlin and Dunn, Soren and Zhang, Lingming},
  journal={arXiv preprint arXiv:2407.01489},
  year={2024}
}

%% Multi-Agent Systems
@article{huang2023agentcoder,
  title={AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation},
  author={Huang, Dong and Bu, Qingwen and Zhang, Jie and Xie, Xiaofei and Chen, Junjie and Cui, Heming},
  journal={arXiv preprint arXiv:2312.13010},
  year={2023}
}

@article{hong2023metagpt,
  title={MetaGPT: Meta Programming for Multi-Agent Collaborative Framework},
  author={Hong, Sirui and Zhuge, Mingchen and Chen, Jonathan and Zheng, Xiawu and Cheng, Yuheng and Zhang, Ceyao and Wang, Jinlin and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and others},
  journal={arXiv preprint arXiv:2308.00352},
  year={2023}
}

%% Prior Work - app.build
@misc{kniazev2025appbuild,
  title={app.build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding},
  author={Kniazev, Evgenii and Kravchenko, Arseny and Rekun, Igor and Broadhead, James and Shamgunov, Nikita and Sah, Pranav and Nichite, Pratik and Yamshchikov, Ivan},
  year={2025},
  eprint={2509.03310},
  archivePrefix={arXiv},
  primaryClass={cs.AI}
}

%% MLflow and Experiment Tracking
@inproceedings{chen2020mlflow,
  title={Developments in MLflow: A System to Accelerate the Machine Learning Lifecycle},
  author={Chen, Andrew and Chow, Andy and Davidson, Aaron and DCamber, Arjun and Ghodsi, Ali and Hong, Sue Ann and Konwinski, Andy and Mewald, Clemens and Murching, Siddharth and Nykodym, Tomas and others},
  booktitle={Proceedings of the Fourth International Workshop on Data Management for End-to-End Machine Learning},
  year={2020}
}

%% Container and Sandboxing
@misc{dagger2024,
  title={Dagger: A Portable Devkit for CI/CD Pipelines},
  author={{Dagger Inc.}},
  year={2024},
  howpublished={\url{https://dagger.io}}
}

%% Vision-Language Models for UI Evaluation
@article{liu2024visual,
  title={Visual Instruction Tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

%% Additional Benchmarks (Added for CAIS 2026)
@article{humanevalpro2024,
  title={HumanEval Pro and MBPP Pro: Evaluating Large Language Models on Self-invoking Code Generation},
  author={Yu, Zhaojian and others},
  journal={arXiv preprint arXiv:2412.21199},
  year={2024}
}

@article{agentbench2023,
  title={AgentBench: Evaluating LLMs as Agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  journal={arXiv preprint arXiv:2308.03688},
  year={2023}
}

@inproceedings{osworld2024,
  title={OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments},
  author={Xie, Tianbao and Zhang, Danyang and Chen, Jixuan and Li, Xiaochuan and Zhao, Siheng and Cao, Ruisheng and Hua, Toh Jing and Cheng, Zhoujun and Shin, Dongchan and Lei, Fangyu and others},
  booktitle={Advances in Neural Information Processing Systems},
  volume={37},
  year={2024}
}

@misc{bigcodebench2024,
  title={BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions},
  author={Zhuo, Terry Yue and Vu, Minh Chien and Chim, Jenny and Hu, Han and Yu, Wenhao and Widyasari, Ratnadira and Yusuf, Imam Nur Bani and Zhan, Haolan and He, Junda and Paul, Indraneil and others},
  journal={arXiv preprint arXiv:2406.15877},
  year={2024}
}

@misc{inspectai2024,
  title={Inspect: A Framework for Large Language Model Evaluations},
  author={{UK AI Safety Institute}},
  year={2024},
  howpublished={\url{https://inspect.aisi.org.uk/}}
}

@misc{deepeval2024,
  title={DeepEval: The LLM Evaluation Framework},
  author={{Confident AI}},
  year={2024},
  howpublished={\url{https://github.com/confident-ai/deepeval}}
}

%% Text-to-SQL Benchmarks
@article{bird2023,
  title={Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQL},
  author={Li, Jinyang and Hui, Binyuan and Qu, Ge and Yang, Jiaxi and Li, Binhua and Li, Bowen and Wang, Bailin and Qin, Bowen and Geng, Ruiying and Huo, Nan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2023}
}

@article{yu2018spider,
  title={Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task},
  author={Yu, Tao and Zhang, Rui and Yang, Kai and Yasunaga, Michihiro and Wang, Dongxu and Li, Zifan and Ma, James and Li, Irene and Yao, Qingning and Roman, Shanelle and others},
  journal={arXiv preprint arXiv:1809.08887},
  year={2018}
}

@article{spider2_2024,
  title={Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows},
  author={Lei, Fangyu and Xie, Tianbao and others},
  journal={arXiv preprint arXiv:2411.07763},
  year={2024}
}

%% Data Analytics Agent Benchmarks
@article{tapilot2024,
  title={Tapilot-Crossing: Benchmarking and Evolving LLMs Towards Interactive Data Analysis Agents},
  author={Li, Jinyang and Huo, Nan and Gao, Yan and Shi, Jiayi and Zhao, Yingxiu and Qu, Ge and Wu, Yurong and Ma, Chenhao and Lou, Jian-Guang and Cheng, Reynold},
  journal={arXiv preprint arXiv:2403.05307},
  year={2024}
}

@article{insightbench2024,
  title={InsightBench: Evaluating Business Analytics Agents Through Multi-Step Insight Generation},
  author={Sahu, Gaurav and others},
  journal={arXiv preprint arXiv:2407.06423},
  year={2024}
}

@article{ds1000_2022,
  title={DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation},
  author={Lai, Yuhang and Li, Chengxi and Wang, Yiming and Zhang, Tianyi and Zhong, Ruiqi and Zettlemoyer, Luke and Yih, Scott Wen-tau and Fried, Daniel and Wang, Sida and Yu, Tao},
  journal={arXiv preprint arXiv:2211.11501},
  year={2022}
}

@article{dabench2024,
  title={InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks},
  author={Hu, Xueyu and others},
  journal={arXiv preprint arXiv:2401.05507},
  year={2024}
}

@article{visualwebarena2024,
  title={VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks},
  author={Koh, Jing Yu and Lo, Robert and Jang, Lawrence and Duvvur, Vikram and Lim, Ming and Huang, Po-Yu and Neubig, Graham and Zhou, Shuyan and Salakhutdinov, Ruslan and Fried, Daniel},
  journal={arXiv preprint arXiv:2401.13649},
  year={2024}
}

%% Prompt Optimization and Self-Reflection
@article{gepa2024,
  title={GEPA: Gradient-based Evolution Prompt Optimization with LLM Agents},
  author={Zhang, Qi and Liu, Xinwei and Chen, Honglin and Guo, Tong},
  journal={arXiv preprint arXiv:2402.00421},
  year={2024}
}

@article{khattab2023dspy,
  title={DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Hruschka, Saiful and Sharma, Ankur and Joshi, Tushar T and Mober, Nikhil and others},
  journal={arXiv preprint arXiv:2310.03714},
  year={2023}
}

%% Tool and CLI Patterns
@misc{cloudflare2024codemode,
  title={Cloudflare Workers AI: Code Mode for Better Tool Use},
  author={{Cloudflare Inc.}},
  year={2024},
  howpublished={\url{https://developers.cloudflare.com/workers-ai/}}
}

@misc{anthropic2024tools,
  title={Tool Use with Claude},
  author={{Anthropic}},
  year={2024},
  howpublished={\url{https://docs.anthropic.com/claude/docs/tool-use}}
}

%% Survey Papers
@article{jiang2024survey,
  title={A Survey on Large Language Models for Code Generation},
  author={Jiang, Jiawei and Wang, Fangkai and Shen, Jingyu and Kim, Sungwook and Kim, Sunghun},
  journal={arXiv preprint arXiv:2406.00515},
  year={2024}
}

@article{paul2024benchmarks,
  title={A Survey of AI Coding Assistants: Current Capabilities and Future Directions},
  author={Paul, Anil and others},
  journal={arXiv preprint arXiv:2409.09186},
  year={2024}
}

%% Reward Hacking / AI Safety
@article{amodei2016concrete,
  title={Concrete Problems in AI Safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

%% OpenHands and Related Work
@inproceedings{wang2024openhands,
  title={OpenHands: An Open Platform for AI Software Developers as Generalist Agents},
  author={Wang, Xingyao and Chen, Boxuan and Luo, Ziyi and Chen, Kexun and Zhang, Hao and Liu, Hoang and Zhang, Xinyu and Deoras, Ankit and others},
  booktitle={ICLR},
  year={2025}
}

%% Metric Clustering
@phdthesis{knyazev2009clustering,
  title={Automated Classification of Source Code Changes Based on Metric Clustering in Software Development},
  author={Knyazev, Evgenii G.},
  year={2009},
  school={Saint Petersburg State University of Information Technologies, Mechanics and Optics (ITMO)},
  note={Originally in Russian. Autoreferat: \url{https://is.ifmo.ru/disser/knyazev_autorefer.pdf}}
}
